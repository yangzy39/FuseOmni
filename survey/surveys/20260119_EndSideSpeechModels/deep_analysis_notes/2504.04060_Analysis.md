# Paper ID: VocalNet: Speech LLM with Multi-Token Prediction (arXiv:2504.04060)

## 1. 核心任务 (Task Definition)
- **现存问题**: Speech LLMs (generating audio codes) are slow due to autoregressive next-token prediction (NTP). Generating 1 second of audio might require hundreds of forward passes (multiple codes per frame).
- **论文解决**: Introduced "VocalNet-1B/8B", applying **Multi-Token Prediction (MTP)** to speech generation.
- **意义**: Significantly speeds up on-device speech generation (critical for TTS latency) without sacrificing quality, enabling "Omni" style interaction on constrained hardware.

## 2. 方法论归类 (Methodology Class)
- **核心类**: Generative Speech Model / Acceleration.
- **核心机制**:
    - **Multi-Token Prediction**: Predicting $n$ future tokens in a single forward pass, instead of just one.
    - **Model-Agnostic Training**: A framework that can be applied to various Transformer backbones.
- **创新点**: First application of MTP (usually used in text LLMs like Medusa) specifically adapted for continuous speech token generation.

## 3. 贡献总结 (Contribution)
- **Speed & Quality**: Simultaneous improvement in speed and quality (rare trade-off).
- **Performance**: Par with mainstream Omni LLMs with limited data.
- **Open Source**: Weights and code released.
