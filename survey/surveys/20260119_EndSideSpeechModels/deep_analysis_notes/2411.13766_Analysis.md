# Paper ID: Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge (arXiv:2411.13766, v2 2025)

## 1. 核心任务 (Task Definition)
- **现存问题**: Integrating ASR + LLM on edge is heavy. Fine-tuning them separately is suboptimal. End-to-end alignment (training projection layers) usually requires HPC (GPUs), making personalized on-device adaptation impossible.
- **论文解决**: Proposed "Tiny-Align", a resource-efficient cross-modal alignment framework for edge devices (e.g., NVIDIA Jetson Orin).
- **意义**: Enables **Personalized On-Device Training**. The model can adapt to a specific user's voice and speech patterns directly on the edge device without sending data to the cloud.

## 2. 方法论归类 (Methodology Class)
- **核心类**: On-Device Training / Efficient Fine-Tuning.
- **核心机制**:
    - **Resource-Aware Alignment**: Optimized gradient updates and memory usage for projection layers between ASR encoder and LLM.
    - **Cross-Modal Optimization**: Jointly optimizing the connector while keeping the LLM backbone frozen (or quantized).
- **创新点**: First work to address the *training* (alignment) cost of multimodal models on constrained edge hardware (8GB RAM), not just inference.

## 3. 贡献总结 (Contribution)
- **Speedup**: 50x training time speedup compared to standard baselines on Jetson Orin.
- **Quality**: Improved alignment quality by >50%.
- **Feasibility**: Proved that personalized alignment of ASR-LLM systems is feasible on high-end edge devices.
