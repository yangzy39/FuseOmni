# REAP-OMNI: å¤šæ¨¡æ€å¤§æ¨¡å‹å‰ªæå·¥å…·åŒ…

<p align="center">
  <img src="https://img.shields.io/badge/Model-Qwen3--Omni--30B-blue" alt="Model">
  <img src="https://img.shields.io/badge/Framework-PyTorch-orange" alt="Framework">
  <img src="https://img.shields.io/badge/License-Apache%202.0-green" alt="License">
</p>

åŸºäº REAP-OMNI å®ç°çš„ **Qwen3-Omni-30B-A3B** å¤šæ¨¡æ€ MoE æ¨¡å‹å‰ªæå·¥å…·åŒ…ï¼Œæ”¯æŒä¸‰ç§å‰ªæç­–ç•¥ï¼š

- ğŸ¯ **è§†è§‰æ¨¡æ€å‰¥ç¦»** - å®Œå…¨ç§»é™¤è§†è§‰ç¼–ç å™¨å’ŒæŠ•å½±å±‚
- ğŸ”§ **REAP ä¸“å®¶å‰ªæ** - åŸºäºéŸ³é¢‘äº²å’Œåº¦çš„ MoE ä¸“å®¶å‰ªæ
- ğŸ“Š **å±‚é—´ç›¸ä¼¼åº¦å‰ªæ** - ç§»é™¤å†—ä½™çš„ Transformer å±‚

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ç®—æ³•åŸç†](#ç®—æ³•åŸç†)
- [å®‰è£…](#å®‰è£…)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†ä½¿ç”¨](#è¯¦ç»†ä½¿ç”¨)
- [æ–‡ä»¶ç»“æ„](#æ–‡ä»¶ç»“æ„)
- [é…ç½®å‚æ•°](#é…ç½®å‚æ•°)
- [ç¤ºä¾‹](#ç¤ºä¾‹)
- [å¼•ç”¨](#å¼•ç”¨)

## æ¦‚è¿°

### èƒŒæ™¯

Qwen3-Omni-30B-A3B æ˜¯ä¸€ä¸ªæ”¯æŒæ–‡æœ¬ã€éŸ³é¢‘ã€è§†é¢‘å¤šæ¨¡æ€è¾“å…¥çš„å¤§å‹ MoEï¼ˆMixture of Expertsï¼‰æ¨¡å‹ï¼š

| ç»„ä»¶ | è§„æ ¼ |
|------|------|
| **è§†è§‰ç¼–ç å™¨** | 27 å±‚, hidden_size=1152, patch_size=16 |
| **éŸ³é¢‘ç¼–ç å™¨** | 32 å±‚, d_model=1280 |
| **Thinker (ä¸»LLM)** | 48 å±‚, 128 ä¸“å®¶, æ¯tokenæ¿€æ´»8ä¸ªä¸“å®¶ |
| **Talker (è¯­éŸ³åˆæˆ)** | 20 å±‚, 128 ä¸“å®¶, æ¯tokenæ¿€æ´»6ä¸ªä¸“å®¶ |
| **æ€»å‚æ•°é‡** | ~35B |

### ç›®æ ‡

æœ¬å·¥å…·åŒ…æ—¨åœ¨å°† Qwen3-Omni å‹ç¼©ä¸º**çº¯éŸ³é¢‘æ¨¡å‹**ï¼Œé€šè¿‡ï¼š

1. **ç§»é™¤è§†è§‰æ¨¡æ€** â†’ å‡å°‘è§†è§‰ç¼–ç å™¨å’ŒæŠ•å½±å±‚å‚æ•°
2. **å‰ªæè§†è§‰ç›¸å…³ä¸“å®¶** â†’ ä¿ç•™éŸ³é¢‘ç›¸å…³çš„ MoE ä¸“å®¶
3. **ç§»é™¤å†—ä½™å±‚** â†’ åŸºäºå±‚é—´ç›¸ä¼¼åº¦å‰ªæ

## ç®—æ³•åŸç†

### 1. è§†è§‰æ¨¡æ€å‰¥ç¦»

ç›´æ¥ä»æ¨¡å‹æƒé‡ä¸­ç§»é™¤æ‰€æœ‰è§†è§‰ç›¸å…³ç»„ä»¶ï¼š

```
ç§»é™¤çš„æƒé‡æ¨¡å¼ï¼š
â”œâ”€â”€ thinker.visual.patch_embed.*      # è§†è§‰ Patch åµŒå…¥
â”œâ”€â”€ thinker.visual.blocks.*           # è§†è§‰ Transformer å—
â”œâ”€â”€ thinker.visual.merger.*           # è§†è§‰æŠ•å½±å±‚
â””â”€â”€ thinker.visual.deepstack_*        # æ·±åº¦å †å è§†è§‰ç‰¹å¾
```

### 2. REAP ä¸“å®¶å‰ªæ

**REAP (Router-weighted Expert Activation Pruning)** é€šè¿‡è®¡ç®—ä¸“å®¶çš„éŸ³é¢‘äº²å’Œåº¦æ¥è¯†åˆ«å’Œä¿ç•™éŸ³é¢‘ç›¸å…³ä¸“å®¶ã€‚

#### ä¸“å®¶æ˜¾è‘—æ€§å…¬å¼

$$S(e, D) = \frac{1}{|D|} \sum_{x \in D} (g_e(x) \cdot \|h_e(x)\|_2)$$

- $g_e(x)$: è·¯ç”±å™¨åˆ†é…ç»™ä¸“å®¶ $e$ çš„é—¨æ§æƒé‡
- $\|h_e(x)\|_2$: ä¸“å®¶ $e$ è¾“å‡ºçš„ L2 èŒƒæ•°

#### éŸ³é¢‘äº²å’Œåº¦åˆ†æ•°

$$\mathcal{A}_{audio}(e) = S_1(e) + \lambda \cdot \text{ReLU}(S_3(e) - \beta \cdot S_2(e))$$

| ç¬¦å· | å«ä¹‰ | é»˜è®¤å€¼ |
|------|------|--------|
| $S_1$ | çº¯éŸ³é¢‘æ•°æ®ä¸Šçš„æ˜¾è‘—æ€§ | - |
| $S_2$ | çº¯è§†é¢‘æ•°æ®ä¸Šçš„æ˜¾è‘—æ€§ | - |
| $S_3$ | æ··åˆæ•°æ®ä¸Šçš„æ˜¾è‘—æ€§ | - |
| $\lambda$ | æ··åˆæ•°æ®æƒé‡ | 1.0 |
| $\beta$ | è§†é¢‘å»å™ªç³»æ•° | 1.0 |

#### å‰ªææµç¨‹

```
1. å¯¹ä¸‰ç§æ•°æ®ç±»å‹è¿è¡Œæ ¡å‡†æ¨ç†
2. è®¡ç®—æ¯ä¸ªä¸“å®¶çš„ S1, S2, S3
3. è®¡ç®—éŸ³é¢‘äº²å’Œåº¦ A_audio
4. æŒ‰ A_audio é™åºæ’åˆ—ä¸“å®¶
5. ä¿ç•™ Top-K ä¸“å®¶ (å¦‚ 50%)
6. ä»æƒé‡æ–‡ä»¶ä¸­ç§»é™¤è¢«å‰ªæçš„ä¸“å®¶
```

### 3. å±‚é—´ç›¸ä¼¼åº¦å‰ªæ

åŸºäºç›¸é‚»å±‚éšè—çŠ¶æ€çš„ç›¸ä¼¼åº¦è¯†åˆ«å†—ä½™å±‚ã€‚**ä½¿ç”¨ä¸ REAP ç¬¬äºŒæ­¥ç›¸åŒçš„éŸ³é¢‘æ ¡å‡†æ•°æ®è¿›è¡Œ forward passï¼Œæ”¶é›†çœŸå®çš„ hidden states ç”¨äºè®¡ç®—å±‚é—´ç›¸ä¼¼åº¦ã€‚**

$$\text{similarity}(H_l, H_{l+1}) = \frac{H_l \cdot H_{l+1}}{\|H_l\| \cdot \|H_{l+1}\|}$$

#### å±‚å‰ªææµç¨‹

```
1. åŠ è½½æ¨¡å‹åˆ° GPU
2. åŠ è½½éŸ³é¢‘æ ¡å‡†æ•°æ®ï¼ˆä¸ REAP step 2 ç›¸åŒæ ¼å¼ï¼‰
3. æ³¨å†Œ forward hooks åœ¨æ¯ä¸ª decoder layer
4. å¯¹æ ¡å‡†æ•°æ®è¿›è¡Œ forward passï¼Œæ”¶é›†æ¯å±‚çš„ hidden states
5. è®¡ç®—ç›¸é‚»å±‚ä¹‹é—´çš„ cosine similarity
6. é€‰æ‹©ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼çš„å±‚ä½œä¸ºå‰ªæå€™é€‰
7. ç§»é™¤å†—ä½™å±‚å¹¶é‡æ–°ç¼–å·å‰©ä½™å±‚
```

ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼ï¼ˆå¦‚ 0.9ï¼‰çš„å±‚è¢«è§†ä¸ºå†—ä½™å±‚å€™é€‰ã€‚

## å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python >= 3.8
- PyTorch >= 2.0
- CUDA >= 11.8 (æ¨è)

### å®‰è£…ä¾èµ–

```bash
pip install torch safetensors tqdm transformers
```

### å…‹éš†ä»“åº“

```bash
git clone https://github.com/your-repo/REAP-OMNI.git
cd REAP-OMNI
```

## å¿«é€Ÿå¼€å§‹

### ä¸€é”®è¿è¡Œå…¨éƒ¨å‰ªæ

**Windows:**
```batch
run_pruning.bat --model-path ..\models\Qwen3-Omni-30B-A3B-Instruct
```

**Linux/Mac/WSL:**
```bash
chmod +x run_pruning.sh
./run_pruning.sh --model-path ../models/Qwen3-Omni-30B-A3B-Instruct
```

### Dry Run é¢„è§ˆ

```bash
# é¢„è§ˆå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶
python vision_strip.py --dry-run
python reap_expert_pruning.py --dry-run
python layer_similarity_pruning.py --dry-run
```

## è¯¦ç»†ä½¿ç”¨

### 1. è§†è§‰æ¨¡æ€å‰¥ç¦»

```bash
python vision_strip.py \
    --model-path ../models/Qwen3-Omni-30B-A3B-Instruct \
    --output-path ../models/Qwen3-Omni-Audio-Only \
    --verbose
```

**å‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--model-path`, `-m` | åŸå§‹æ¨¡å‹è·¯å¾„ | - |
| `--output-path`, `-o` | è¾“å‡ºæ¨¡å‹è·¯å¾„ | - |
| `--dry-run` | ä»…åˆ†æä¸ä¿®æ”¹ | False |
| `--device` | è®¡ç®—è®¾å¤‡ | cuda |
| `--no-copy-unaffected` | ä¸å¤åˆ¶æœªä¿®æ”¹çš„åˆ†ç‰‡ | False |

### 2. REAP ä¸“å®¶å‰ªæ

```bash
python reap_expert_pruning.py \
    --model-path ../models/Qwen3-Omni-30B-A3B-Instruct \
    --output-path ../models/Qwen3-Omni-REAP-50 \
    --component thinker \
    --retention-rate 0.5 \
    --verbose
```

**ä½¿ç”¨æ ¡å‡†æ•°æ®ï¼š**

```bash
python reap_expert_pruning.py \
    --model-path ../models/Qwen3-Omni-30B-A3B-Instruct \
    --output-path ../models/Qwen3-Omni-REAP-50 \
    --audio-data ./calibration/audio.jsonl \
    --video-data ./calibration/video.jsonl \
    --mixed-data ./calibration/mixed.jsonl \
    --retention-rate 0.5
```

**å‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--component` | å‰ªæç»„ä»¶ (thinker/talker) | thinker |
| `--retention-rate`, `-r` | ä¸“å®¶ä¿ç•™æ¯”ä¾‹ (0.0-1.0) | 0.5 |
| `--lambda-weight` | æ··åˆæ•°æ®æƒé‡ Î» | 1.0 |
| `--beta-weight` | è§†é¢‘å»å™ªç³»æ•° Î² | 1.0 |
| `--audio-data` | éŸ³é¢‘æ ¡å‡†æ•°æ®è·¯å¾„ (JSONL) | None |
| `--video-data` | è§†é¢‘æ ¡å‡†æ•°æ®è·¯å¾„ (JSONL) | None |
| `--mixed-data` | æ··åˆæ ¡å‡†æ•°æ®è·¯å¾„ (JSONL) | None |
| `--calibration-samples` | æ¯ç§æ¨¡æ€çš„æ ¡å‡†æ ·æœ¬æ•° | 100 |

### 3. å±‚é—´ç›¸ä¼¼åº¦å‰ªæ

**æ¨èæ–¹å¼ï¼šä½¿ç”¨éŸ³é¢‘æ ¡å‡†æ•°æ®ï¼ˆä¸ REAP step 2 ç›¸åŒï¼‰**

```bash
python layer_similarity_pruning.py \
    --model-path ../models/Qwen3-Omni-30B-A3B-Instruct \
    --output-path ../models/Qwen3-Omni-Layer-Pruned \
    --audio-data ./calibration/audio.jsonl \
    --component thinker \
    --similarity-threshold 0.9 \
    --max-layers 8 \
    --verbose
```

**Dry Run æ¨¡å¼ï¼šä»…æŸ¥çœ‹å±‚é—´ç›¸ä¼¼åº¦ï¼Œä¸æ‰§è¡Œå‰ªæ**

```bash
python layer_similarity_pruning.py \
    --audio-data ./calibration/audio.jsonl \
    --dry-run
```

**é™æ€æ¨¡å¼ï¼šæ‰‹åŠ¨æŒ‡å®šè¦å‰ªæçš„å±‚ï¼ˆæ— éœ€åŠ è½½æ¨¡å‹ï¼‰**

```bash
python layer_similarity_pruning.py \
    --static \
    --prune-layers 12 16 20 24 28 32
```

**å‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--component` | å‰ªæç»„ä»¶ (thinker/talker) | thinker |
| `--audio-data` | éŸ³é¢‘æ ¡å‡†æ•°æ®è·¯å¾„ (JSONLï¼Œä¸ REAP step 2 ç›¸åŒæ ¼å¼) | None |
| `--calibration-samples` | ä½¿ç”¨çš„æ ¡å‡†æ ·æœ¬æ•° | 32 |
| `--similarity-threshold`, `-t` | ç›¸ä¼¼åº¦é˜ˆå€¼ | 0.9 |
| `--max-layers` | æœ€å¤§å‰ªæå±‚æ•° | 8 |
| `--prune-layers` | æ‰‹åŠ¨æŒ‡å®šè¦å‰ªæçš„å±‚ç´¢å¼• | None |
| `--protect-first` | ä¿æŠ¤å‰ N å±‚ä¸å‰ªæ | 4 |
| `--protect-last` | ä¿æŠ¤å N å±‚ä¸å‰ªæ | 4 |
| `--layers-to-skip` | æ¯”è¾ƒé—´éš” (1=ç›¸é‚»å±‚) | 1 |
| `--static` | é™æ€æ¨¡å¼ï¼šä¸åŠ è½½æ¨¡å‹ï¼Œéœ€é…åˆ --prune-layers | False |
| `--device` | æ¨¡å‹åŠ è½½è®¾å¤‡ | cuda |
| `--dtype` | æ¨¡å‹ç²¾åº¦ (bfloat16/float16/float32) | bfloat16 |

## æ–‡ä»¶ç»“æ„

```
REAP-OMNI/
â”œâ”€â”€ README.md                      # æœ¬æ–‡æ¡£
â”œâ”€â”€ reap-omni.pdf                  # å‚è€ƒè®ºæ–‡
â”œâ”€â”€ vision_strip.py                # è§†è§‰æ¨¡æ€å‰¥ç¦»
â”œâ”€â”€ reap_expert_pruning.py         # REAP ä¸“å®¶å‰ªæ
â”œâ”€â”€ layer_similarity_pruning.py    # å±‚é—´ç›¸ä¼¼åº¦å‰ªæ
â”œâ”€â”€ run_pruning.sh                 # Linux/Mac æ‰§è¡Œè„šæœ¬
â””â”€â”€ run_pruning.bat                # Windows æ‰§è¡Œè„šæœ¬
```

## é…ç½®å‚æ•°

### æ ¡å‡†æ•°æ®æ ¼å¼

æ ¡å‡†æ•°æ®ä½¿ç”¨ JSONL æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªæ ·æœ¬ï¼š

```json
{"id": "sample_001", "text": "éŸ³é¢‘è½¬å½•æ–‡æœ¬æˆ–æè¿°", "modality": "audio"}
{"id": "sample_002", "text": "è§†é¢‘æè¿°æ–‡æœ¬", "modality": "video"}
{"id": "sample_003", "text": "éŸ³è§†é¢‘æ··åˆæè¿°", "modality": "mixed"}
```

### æ¨èé…ç½®

| å‹ç¼©ç›®æ ‡ | è§†è§‰å‰¥ç¦» | ä¸“å®¶ä¿ç•™ç‡ | å±‚å‰ªææ•° | é¢„è®¡å‹ç¼©æ¯” |
|----------|----------|------------|----------|------------|
| è½»åº¦å‹ç¼© | âœ“ | 75% | 4 | ~30% |
| ä¸­åº¦å‹ç¼© | âœ“ | 50% | 8 | ~50% |
| æ¿€è¿›å‹ç¼© | âœ“ | 25% | 12 | ~70% |

## ç¤ºä¾‹

### å®Œæ•´æµæ°´çº¿ç¤ºä¾‹

```bash
#!/bin/bash
# å®Œæ•´çš„ REAP-OMNI å‹ç¼©æµæ°´çº¿

MODEL_PATH="./models/Qwen3-Omni-30B-A3B-Instruct"
OUTPUT_BASE="./models"

# Step 1: è§†è§‰æ¨¡æ€å‰¥ç¦»
echo "Step 1: Stripping vision modality..."
python vision_strip.py \
    --model-path $MODEL_PATH \
    --output-path $OUTPUT_BASE/step1-vision-stripped

# Step 2: REAP ä¸“å®¶å‰ªæ (ä¿ç•™50%ä¸“å®¶)
echo "Step 2: REAP expert pruning..."
python reap_expert_pruning.py \
    --model-path $OUTPUT_BASE/step1-vision-stripped \
    --output-path $OUTPUT_BASE/step2-reap-pruned \
    --retention-rate 0.5

# Step 3: å±‚å‰ªæï¼ˆä½¿ç”¨éŸ³é¢‘æ ¡å‡†æ•°æ®è®¡ç®—çœŸå®ç›¸ä¼¼åº¦ï¼‰
echo "Step 3: Layer similarity pruning..."
python layer_similarity_pruning.py \
    --model-path $OUTPUT_BASE/step2-reap-pruned \
    --output-path $OUTPUT_BASE/final-compressed \
    --audio-data ./calibration/audio.jsonl \
    --max-layers 8 \
    --similarity-threshold 0.9

echo "Done! Compressed model saved to: $OUTPUT_BASE/final-compressed"
```

### Python API ä½¿ç”¨

```python
from vision_strip import VisionWeightStripper
from reap_expert_pruning import REAPExpertPruner, REAPConfig
from layer_similarity_pruning import LayerSimilarityPruner, LayerPruningConfig

# 1. è§†è§‰å‰¥ç¦»
stripper = VisionWeightStripper(
    model_path="./models/Qwen3-Omni-30B-A3B-Instruct",
    output_path="./models/vision-stripped"
)
stats = stripper.strip_vision_weights()
print(f"Removed {stats['vision_weights']} vision weights")

# 2. REAP ä¸“å®¶å‰ªæ
config = REAPConfig(
    model_path="./models/vision-stripped",
    output_path="./models/reap-pruned",
    retention_rate=0.5,
    component="thinker"
)
pruner = REAPExpertPruner(config)
stats = pruner.run_static_pruning()
print(f"Kept {stats['weights_to_keep']} weights")

# 3. å±‚å‰ªæï¼ˆä½¿ç”¨éŸ³é¢‘æ ¡å‡†æ•°æ®ï¼‰
config = LayerPruningConfig(
    model_path="./models/reap-pruned",
    output_path="./models/layer-pruned",
    audio_data_path="./calibration/audio.jsonl",
    similarity_threshold=0.9,
    max_layers_to_prune=8
)
pruner = LayerSimilarityPruner(config)
stats = pruner.run_with_calibration()  # åŠ è½½æ¨¡å‹ï¼Œforward passï¼Œè®¡ç®—çœŸå®ç›¸ä¼¼åº¦
print(f"Pruned {stats['layers_pruned']} layers")
```

## æ³¨æ„äº‹é¡¹

1. **ç£ç›˜ç©ºé—´**: æ¯ä¸ªå‰ªææ­¥éª¤ä¼šåˆ›å»ºæ–°çš„æ¨¡å‹å‰¯æœ¬ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
2. **å†…å­˜éœ€æ±‚**: å¤„ç†å¤§å‹ safetensor åˆ†ç‰‡æ—¶éœ€è¦è¶³å¤Ÿçš„ RAM
3. **GPU æ˜¾å­˜**: å±‚å‰ªæä½¿ç”¨æ ¡å‡†æ¨¡å¼æ—¶éœ€è¦åŠ è½½å®Œæ•´æ¨¡å‹ï¼Œå»ºè®®ä½¿ç”¨ 80GB+ æ˜¾å­˜çš„ GPU
4. **å¤‡ä»½åŸæ¨¡å‹**: å»ºè®®åœ¨å‰ªæå‰å¤‡ä»½åŸå§‹æ¨¡å‹
5. **éªŒè¯è¾“å‡º**: å‰ªæåå»ºè®®è¿è¡Œæ¨ç†æµ‹è¯•éªŒè¯æ¨¡å‹åŠŸèƒ½
6. **æ ¡å‡†æ•°æ®å¤ç”¨**: å±‚å‰ªæä½¿ç”¨ä¸ REAP step 2 ç›¸åŒçš„éŸ³é¢‘æ ¡å‡†æ•°æ®æ ¼å¼ï¼Œå¯å¤ç”¨

## å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨äº†æœ¬å·¥å…·åŒ…ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{reap-omni,
  title={REAP-OMNI: Multimodal Model Pruning for Audio-focused Applications},
  author={...},
  year={2025}
}
```

## å‚è€ƒèµ„æ–™

- [REAP: Cerebras Research](https://github.com/CerebrasResearch/reap)
- [PruneMe: Layer Similarity Pruning](https://github.com/arcee-ai/PruneMe)
- [FlowCut: Vision Token Pruning](https://github.com/TungChintao/FlowCut)
- [Qwen3-Omni Official](https://github.com/QwenLM/Qwen)

## License

Apache License 2.0
